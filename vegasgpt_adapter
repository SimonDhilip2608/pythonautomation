# Optional Advanced Implementation - Adapter Pattern for VegasGPT

# Create this file as services/vegasgpt_adapter.py

import logging
import json
from datetime import datetime

logger = logging.getLogger(__name__)

class VegasGPTAdapter:
    """Adapter pattern to abstract VegasGPT interactions and improve reliability."""
    
    def __init__(self, vegasgpt_service):
        self.service = vegasgpt_service
        
    def analyze_logs(self, logs):
        """Process logs through VegasGPT with multiple fallback strategies."""
        # If no service or no logs, return empty analysis
        if not self.service or not logs:
            return self._create_empty_analysis()
        
        # First try standard analysis
        result = self._try_standard_analysis(logs)
        
        # If standard analysis failed, try progressive fallbacks
        if not self._is_valid_analysis(result):
            logger.warning("Standard analysis failed, trying alternative prompt")
            result = self._try_alternative_prompt(logs)
            
            if not self._is_valid_analysis(result):
                logger.warning("Alternative prompt failed, trying direct error extraction")
                result = self._try_manual_extraction(logs)
        
        return result
    
    def _is_valid_analysis(self, analysis):
        """Check if the analysis result is valid and contains errors."""
        if not analysis:
            return False
            
        errors = analysis.get('errors', [])
        
        # An analysis is valid if it has a properly formed structure with errors
        # or it explicitly indicates no errors were found with a proper summary
        return (isinstance(errors, list) and errors) or \
               (isinstance(errors, list) and analysis.get('summary') and 'no error' in analysis.get('summary', '').lower())
    
    def _try_standard_analysis(self, logs):
        """Try the standard VegasGPT analysis."""
        try:
            return self.service.analyze_logs(logs)
        except Exception as e:
            logger.error(f"Error in standard analysis: {str(e)}")
            return None
    
    def _try_alternative_prompt(self, logs):
        """Try an alternative prompt strategy."""
        try:
            # Create a simpler, more direct prompt focusing just on error detection
            log_text = self._format_logs_for_analysis(logs)
            
            prompt = f"""
            Analyze these system logs and list each error found:
            
            {log_text}
            
            Return ONLY a JSON with this structure:
            {{
                "errors": [
                    {{
                        "message": "Error message",
                        "root_cause": "Likely cause",
                        "severity": "High/Medium/Low",
                        "timestamp": "Time"
                    }}
                ],
                "summary": "Brief summary"
            }}
            """
            
            # Use a more restrictive temperature and higher max_tokens
            return self.service.analyze_with_custom_prompt(prompt, temperature=0.1, max_tokens=5000)
        except Exception as e:
            logger.error(f"Error in alternative prompt: {str(e)}")
            return None
    
    def _try_manual_extraction(self, logs):
        """Extract errors directly from logs without AI."""
        try:
            return self.service.extract_errors_manually(logs)
        except Exception as e:
            logger.error(f"Error in manual extraction: {str(e)}")
            return self._create_empty_analysis()
    
    def _format_logs_for_analysis(self, logs):
        """Format logs in a way optimized for VegasGPT analysis."""
        formatted_logs = []
        
        for log in logs:
            level = log.get('level', '').upper()
            message = log.get('message', '')
            timestamp = log.get('timestamp', '')
            service = log.get('service', '')
            
            # Format differently based on log type for better analysis
            if level in ['ERROR', 'SEVERE']:
                formatted_logs.append(f"[ERROR][{timestamp}] [{service}] {message}")
            elif 'Exception' in message or 'Error:' in message:
                formatted_logs.append(f"[ERROR-CONTENT][{timestamp}] [{service}] {message}")
            else:
                formatted_logs.append(f"[{level}][{timestamp}] [{service}] {message}")
        
        return '\n'.join(formatted_logs)
    
    def _create_empty_analysis(self):
        """Create an empty analysis result."""
        return {
            "errors": [],
            "summary": "No errors could be detected in the logs.",
            "extraction_method": "empty"
        }

# Add this method to your VegasGPTService class:

def analyze_with_custom_prompt(self, prompt, temperature=0.2, max_tokens=4000):
    """Analyze logs with a custom prompt and parameters."""
    if not self.is_configured():
        logger.error("AI Service is not configured properly")
        return {"errors": [], "summary": "Error: AI service not configured."}
        
    try:
        data = {
            "variables": {
                "prompt": prompt
            },
            "model": "VEGAS",
            "model_settings": {
                "temperature": temperature,
                "max_output_tokens": max_tokens
            }
        }
        
        inference_url = f"{self.agents_url}/inference/generate"
        headers = {
            'X-api-key': self.agents_token,
            'Content-Type': 'application/json'
        }
        
        logger.debug("Sending custom prompt to VegasGPT")
        
        response = requests.post(inference_url, json=data, headers=headers, timeout=60)
        
        if response.status_code != 200:
            logger.error(f"AI API error with custom prompt: {response.status_code}")
            return {
                "errors": [],
                "summary": f"Error from AI service: {response.status_code}"
            }
        
        ai_response = response.json().get('ai_response', '')
        
        try:
            json_start = ai_response.find('{')
            json_end = ai_response.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = ai_response[json_start:json_end]
                analysis = json.loads(json_str)
                
                return analysis
            else:
                return {
                    "errors": [],
                    "summary": "Could not extract structured data from AI response."
                }
        except json.JSONDecodeError:
            return {
                "errors": [],
                "summary": "Could not parse JSON in the AI response."
            }
            
    except Exception as e:
        logger.error(f"Error with custom prompt analysis: {str(e)}")
        return {
            "errors": [],
            "summary": f"Error during analysis: {str(e)}"
        }
